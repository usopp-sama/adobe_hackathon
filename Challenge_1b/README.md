# ğŸ§  Challenge 1B â€“ Semantic Matcher for PDFs

## ğŸ” Task Outline

Given a task description and a set of PDF documents, build a system that:

* Extracts structured semantic content from PDFs
* Matches the task against document content using semantic similarity
* Returns top-ranked, summarized sections with metadata in a specified JSON schema

## ğŸ§± Project Outline

This system processes multiple collections of PDFs to semantically extract and rank relevant sections based on a business task. It includes:

* Document parsing with heading/paragraph detection
* NLP-based semantic token extraction
* Embedding generation and similarity scoring
* Summarization of matched content
* Final output formatting in JSON

## ğŸ’¡ Explanation of the Idea

1. **PDF Parsing**: Each PDF is processed using layout heuristics and font-based heading detection to extract clean, semantically annotated sections.
2. **Task Matching**: A `job_to_be_done` task is compared with all document sections using Sentence-BERT embeddings (`MiniLM`).
3. **Summarization**: Top-matched sections are summarized using `Flan-T5-small` to provide a concise business-friendly overview.
4. **Output**: The results are saved in the required output schema, including metadata, matched sections, and their summaries.

---

## ğŸ³ How to Build and Run

### ğŸ”§ Step 1: Build Docker Image

```bash
docker build -t semantic-matcher .
```

or

```bash
DOCKER_BUILDKIT=0 docker build -t semantic-matcher .
```

### ğŸš€ Step 2: Run the Matcher

```bash
docker run --rm -v $(pwd)/collections:/app/collections \
           -v $(pwd)/outputs:/app/outputs \
           semantic-matcher
```

Make sure you have the `collections/` folder structured with:

```
collections/
â”œâ”€â”€ Collection 1/
â”‚   â”œâ”€â”€ challenge1b_input.json
â”‚   â”œâ”€â”€ PDFs/
â”‚   â””â”€â”€ json_output/    # Will be auto-created
â”œâ”€â”€ Collection 2/
â”œâ”€â”€ Collection 3/
```

---

## ğŸ“ Directory Structure

```
Challenge_1b/
â”œâ”€â”€ collections/                 # Input collections of PDFs
â”‚   â”œâ”€â”€ Collection 1/
â”‚   â”‚   â”œâ”€â”€ challenge1b_input.json
â”‚   â”‚   â”œâ”€â”€ PDFs/
â”‚   â”‚   â””â”€â”€ json_output/        # Output JSONs per PDF (auto-filled)
â”‚   â”œâ”€â”€ Collection 2/
â”‚   â””â”€â”€ Collection 3/
â”œâ”€â”€ outputs/                    # Final results saved here
â”œâ”€â”€ Dockerfile                 # Docker container setup
â”œâ”€â”€ nlp_utils.py               # NLP utilities (shared with 1A)
â”œâ”€â”€ pdf_processor_pipeline.py  # PDF parsing and semantic extraction (shared with 1A)
â”œâ”€â”€ semantic_matcher.py        # Main semantic matching pipeline
â”œâ”€â”€ requirements.txt           # All Python dependencies
â””â”€â”€ README.md                  # This file
```

---

## ğŸ” Output Schema (Summary)

Each output JSON has:

* `metadata`: input files, persona, job task, timestamp
* `extracted_sections`: ranked sections with heading and page
* `subsection_analysis`: summaries per matched section

---

## ğŸ‘¥ Authors

* **Anagh Verma**
* **Ashutosh Bhardwaj**
* **Rishit Mohan**
  Adobe India Hackathon 2025 â€“ Challenge 1B Contributors

---

